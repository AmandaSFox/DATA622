---
title: "DATA_622_Project_1"
author: "Fox"
date: "3/2/2025"
format: html
---

## 1. Introduction

This assignment focuses on **Exploratory Data Analysis (EDA)**, one of the most important steps in data science. Surveys show data scientists spend 60-80% of their time on data prep, and EDA helps *identify data gaps, improve quality, and shape better features* — all leading to better models.

The dataset comes from a study by Moro, Cortez, and Rita conducted between 2008 and 2013, where they analyzed telemarketing data from a Portuguese bank to predict the success of selling long-term deposits. The research team applied feature selection and modeling techniques, ultimately comparing logistic regression, decision trees, neural networks, and support vector machines to find the best predictive model. 

For this EDA, I’m using a ***pre-processed version*** of that original dataset, which has a reduced number of features and shows evidence that it has been thoroughly cleaned, as we will see. 

```{r libraries, message = FALSE, warning = FALSE}
library(tidyverse)
library(ggplot2)
library(purrr)
library(knitr)
library(scales)
library(reshape2)
library(GGally)
```

## 2. Dataset Overview

The dataset contains ***45,211 records and 17 columns***. There are ***no missing values and no duplicate records***: as we go through this EDA exercise, it will become increasingly clear that this dataset has been thoroughly cleaned.

```{r overview, message = FALSE, warning = FALSE}

df <- read_delim("https://raw.githubusercontent.com/AmandaSFox/DATA622/refs/heads/main/Assignment_1/bank-full.csv",
                 delim = ";",
                 quote = "\"")

glimpse(df)

colSums(is.na(df))

nrow(df) - nrow(distinct(df))

```
The data consists of bank customers who were contacted as part of a marketing campaign and the features describe customer demographics, financial history, and characteristics of their interactions, as well as a label "y" which indicates whether they did choose the new deposit account.

Before doing further analysis, I changed the column names to be more meaningful: this is my personal preference so that I can more clearly see how the data stacks up against my expectations based on my business knowledge.

Now let's *get to know our population*, starting with the categorical variables:

``` {r col_names}
df_final <- df %>% 
  set_names("Age","Occupation","Marital_Status","Education",
            "In_Default","Avg_Balance","Housing_Loan","Personal_Loan",
            "Contact_Type","Day","Month","Duration","Contacts_This_Campaign",
            "Days_Since_Last_Campaign","Contacts_Before_This_Campaign",
            "Previous_Outcome","Y")
```

## 3. Exploring the Data

Simple frequency distributions of the categorical variables were done to check for class imbalance. Overall, this data paints a picture of a ***financially stable, middle-class, working-age adult population***: typical of *target customers for banking products*. 

It should also be noted here again that this data is *extremely clean*: just as there are no missing values, there are no clearly incorrect values (e.g. misspellings, upper/lower case issues, values appearing in the wrong columns/truncated/concatenated/etc.). 

Regarding the target population:

**1. Most target customers were employed**: There were eight occupation categories comprising **89.4%** of the population, with blue-collar (21.5%), management (20.9%), and technician (16.8%) being the most common categories. Only 10.0% of customers were not currently employed (retired, unemployed, student) and 0.6% were unknown.  
  
**2. Education varied** in rough alignment with the occupations above: 29.4% had tertiary education, 51.3% secondary, 15.2% primary
  
**3. Most were married (60.2%)**
  
**4. They were financially stable**: 98.2% were not in default, 55.6% had housing loans and only 16% had personal loans. 
  
The "previous outcome" field is interesting: *3.3% of previous interactions were deemed "successes,"* which raises the question why they were called again. 81.7% were "unknown" and 4.1% "other," so I *do not believe this field is very meaningful*. 
  
Finally, ***11.4% of contacts were successful*** in selling the product, the goal of the marketing outreach: this is our **label** for supervised ML.
  
``` {r frequencies}

# categorical column list
cat_cols <- df_final %>% 
  select(where(is.character)) %>%  
  names()

for (col in cat_cols) {
   df_final %>%
    count(.data[[col]]) %>%
    mutate(Pct = round((n / sum(n)) * 100, 1)) %>%
    arrange(desc(Pct)) %>% 
    print()
}

```

Next, we look at our numeric variables for central tendency, spread, and outliers. 

To complete our demographic analysis, I first analyzed **Age**, which shows a solid, *mostly working-age adult population* in alignment with a bank's target customer base:
  
```{r num_dist}
# numerical column list: removed "Day" as it is not a meaningful number
df_num <- df_final %>% 
  select(-Day) %>% 
  select(where(is.numeric))

# Age
summary(df_num$Age)

plot_age <- df_num %>% 
  ggplot(aes(Age))+
    geom_histogram(bins = 30,fill="seagreen") +
    scale_x_continuous(breaks = seq(0, 100, by = 5)) +
    theme_minimal()
print(plot_age)

```

Another numeric column (Avg Balance) tells us more about their financial health. Note that *most people owed very little with a few owing quite a lot*: given the extreme right skew, this histogram is zoomed in to focus on balances below $5000. 
  
**Average annual balance**: The median annual average balance owed was only \$448, with a narrow IQR of \$1,480. The max was high but reasonable at \$102,127, and there were some small negative balances owed, likely reflecting overpaid accounts. These outliers and negative values will be *left alone* as they are realistic and potentially meaningful.
  
``` {r bal_zoom}

summary(df_num$Avg_Balance)

df_num %>% 
  ggplot(aes(x = Avg_Balance)) +
    geom_histogram(bins = 1000, fill = "gray80") +
    geom_vline(xintercept = 0, color="black", linetype = "dashed") +
    coord_cartesian(c(-1000,8000)) +
    scale_x_continuous(breaks = seq(-1000, 8000, by = 1000)) +
    theme_minimal() +
    labs(title = "Avg Annual Balance: Zoomed")
    
```

The remaining numeric variables describe the outreach itself:

**1. Median call duration** was 180 seconds, with the longest call = 4918 seconds or over an hour and 20 minutes long. The IQR was 216 seconds, with 50% of calls lasting between 103 and 319 seconds. No negative numbers were found. The outliers will be *left alone* as they are realistic for long phone calls.
  
**2. Contacts before this campaign**: This was the first campaign for a large majority of customers (81.9%)

**3. Contacts this campaign**: The median # of contacts this campaign was two calls, with an IQR of two. The min was one call, which makes sense, but the max ranged up to 63: this seems unusual and could possibly be a data issue but we will *leave these outliers alone* for now. 

**4. Days since last campaign**: This is the first *potential problem* in the data: the 81.7% of first-time outreach customers are denoted here as -1 days since last campaign, which will cause statistical and mathematical issues (see summary for an example). *These might be better changed to NA*. Ignoring these for now, the histogram below shows values >0, which vary widely with no particular pattern. I'm not clear on the value of this data from a business perspective, but we will see.

``` {r outreach, message = FALSE, warning = FALSE}
# Call Duration
summary(df_num$Duration)

ggplot(df_num, aes(x = Duration)) +
  geom_histogram(bins = 60, fill = "skyblue") +
  theme_minimal() +
  coord_cartesian(c(-100,2000)) +
  scale_x_continuous(breaks = seq(0, 2000, by = 200)) +
  labs(title = "Call Duration in Seconds: Zoomed")

# Contacts Before This Campaign
summary(df_num$Contacts_Before_This_Campaign)

df_final %>% 
  count(Contacts_Before_This_Campaign) %>% 
#  mutate(Pct = round((n / sum(n)) * 100, 1))
  mutate(
    Contacts = ifelse(Contacts_Before_This_Campaign <= 5, 
                      as.character(Contacts_Before_This_Campaign), 
                      ">5"),
    Pct = round((n / sum(n)) * 100, 1)
  ) %>%
  group_by(Contacts) %>%
  summarise(n = sum(n), Pct = sum(Pct)) %>%
  arrange(as.numeric(Contacts)) %>% 
  print(n = Inf)  # Show all rows (helpful in case there's 0-9 and "Other")

# Contacts This Campaign
summary(df_num$Contacts_This_Campaign)

df_final %>% 
  count(Contacts_This_Campaign) %>% 
#  mutate(Pct = round((n / sum(n)) * 100, 1))
  mutate(
    Contacts = ifelse(Contacts_This_Campaign <= 9, 
                      as.character(Contacts_This_Campaign), 
                      ">9"),
    Pct = round((n / sum(n)) * 100, 1)
  ) %>%
  group_by(Contacts) %>%
  summarise(n = sum(n), Pct = sum(Pct)) %>%
  arrange(as.numeric(Contacts)) %>% 
  print(n = Inf)  # Show all rows (helpful in case there's 0-9 and "Other")

# Days Since Last Campaign
summary(df_num$Days_Since_Last_Campaign)

df_final %>% 
  count(Days_Since_Last_Campaign) %>% 
#  mutate(Pct = round((n / sum(n)) * 100, 1))
  mutate(
    Days = ifelse(Days_Since_Last_Campaign <= 5, 
                      as.character(Days_Since_Last_Campaign), 
                      ">5"),
    Pct = round((n / sum(n)) * 100, 1)
  ) %>%
  group_by(Days) %>%
  summarise(n = sum(n), Pct = sum(Pct)) %>%
  arrange(as.numeric(Days)) %>% 
  print()

df_days_gt_0 <- df_num %>% 
  select(Days_Since_Last_Campaign) %>% 
  filter(Days_Since_Last_Campaign > 0)

ggplot(df_days_gt_0, aes(x = Days_Since_Last_Campaign)) +
  geom_histogram(bins = 60, fill = "skyblue") +
  theme_minimal() +
  coord_cartesian(c(-100,2000)) +
  scale_x_continuous(breaks = seq(0, 2000, by = 200)) +
  labs(title = "Days Since Last Campaign: >0 Days")


```

## 4. Relationships Between Variables

### 4.1 Numeric vs Numeric - Correlation Analysis

A correlation matrix was computed to identify relationships between numeric features. No significant correlations were found, in fact, *only one pair of numeric columns had a correlation coefficient (absolute value) over 0.1*: "contacts before this campaign" and "days since last campaign". This makes sense as most (81.4%) of people contacted had zero contacts before this campaign and therefore had a value of -1 days since last campaign.
  
``` {r cor_matrix}

cor_matrix <- df_num %>% 
  cor(use = "pairwise.complete.obs")

# table of pairs with coefficients
cor_df <- as.data.frame(as.table(cor_matrix)) %>%
  filter(Var1 != Var2) %>%                    
  filter(abs(Freq) > 0.1) %>%
  arrange(desc(abs(Freq)))

cor_df

# plot
melt_cor <- melt(cor_matrix)

ggplot(melt_cor, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white",
                       midpoint = 0, limit = c(-1,1), space = "Lab",
                       name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  coord_fixed()

```

I also tried ggally and scatterplots in case there were non-linear patterns, but they showed no patterns. 

The lack of correlation among these columns is more evidence that this dataset was thoroughly pre-processed. 


### 4.2 Numeric vs Categorical - Boxplots
  
Boxplots were used to review how numeric features (e.g., age, balance, duration) vary across categorical groups like job, education, and marital.

{r
Copy
Edit
for (cat in categorical_cols) {
  for (num in numeric_cols) {
    ggplot(df, aes_string(x = cat, y = num)) +
      geom_boxplot(outlier.color = "red", outlier.shape = 1) +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      labs(title = paste(num, "by", cat)) %>%
      print()
  }
}
### 4.3 Categorical vs Categorical - Stacked Bar Charts
Relationships between categorical variables were visualized using stacked bar charts.

{r
Copy
Edit
if (length(categorical_cols) > 1) {
  for (i in 1:(length(categorical_cols) - 1)) {
    for (j in (i + 1):length(categorical_cols)) {
      cat1 <- categorical_cols[i]
      cat2 <- categorical_cols[j]
      
      ggplot(df, aes_string(x = cat1, fill = cat2)) +
        geom_bar(position = "fill") +
        scale_y_continuous(labels = label_percent()) +
        labs(title = paste("Proportion of", cat2, "within", cat1),
             y = "Proportion") +
        theme_minimal() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) %>%
        print()
    }
  }
}


### Summary of Key Findings
The dataset is clean and ready for modeling, with no missing values, duplicates, or data quality issues.
Numeric variables are mostly independent, with no strong correlations, which simplifies model selection.
Categorical variables exhibit some class imbalance, particularly in job, which may require consideration in model training.
No surprising or unexpected patterns were found; the data aligns with reasonable expectations for a financial marketing campaign.




## Works Cited

ChatGPT. “ChatGPT.” Chatgpt.com, 2024, chatgpt.com. Accessed Feb. 2025.  
  R coding assistance.  

Moro, Sérgio et al. “A data-driven approach to predict the success of bank
  telemarketing.” Decis. Support Syst. 62 (2014): 22-31. 

Moro, S., P. Rita, and P. Cortez. "Bank Marketing." UCI Machine Learning 
  Repository, 2014, https://doi.org/10.24432/C5K306. Accessed Feb. 2025.